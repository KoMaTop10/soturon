{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default import \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from math import sqrt\n",
    "# learners\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#\n",
    "from sklearn.model_selection import train_test_split \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 使用するモデルの定義\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(GradientBoostingClassifier())\n",
    "    models.append(LogisticRegression(solver='liblinear'))\n",
    "#     models.append(DecisionTreeClassifier())\n",
    "    models.append(SVC(gamma='scale', probability=True))\n",
    "    models.append(GaussianNB())\n",
    "    models.append(KNeighborsClassifier())\n",
    "    models.append(AdaBoostClassifier())\n",
    "    models.append(BaggingClassifier(n_estimators=10))\n",
    "    models.append(RandomForestClassifier(n_estimators=10))\n",
    "    models.append(ExtraTreesClassifier(n_estimators=10))\n",
    "    return models\n",
    "\n",
    "\n",
    "# super learner に用いる特徴量の作成\n",
    "def get_out_of_fold_predictions(X, y, models):\n",
    "    meta_X, meta_y = list(),list()\n",
    "    kfold = KFold(n_splits=10,shuffle =True)\n",
    "    for train_ix,test_ix in kfold.split(X):\n",
    "        \n",
    "        fold_yhats = list()\n",
    "\n",
    "        train_X, test_X = X[train_ix],X[test_ix]\n",
    "        train_y, test_y = y[train_ix],y[test_ix]\n",
    "        meta_y.extend(test_y)#ここよくわからん\n",
    "#         print(len(test_X))\n",
    "        \n",
    "        for model in models:\n",
    "            model.fit(train_X,train_y)\n",
    "            yhat = model.predict(test_X)\n",
    "            \n",
    "            fold_yhats.append(yhat.reshape(len(yhat),1))\n",
    "        meta_X.append(np.hstack(fold_yhats))\n",
    "    return np.vstack(meta_X),np.asarray(meta_y)\n",
    "\n",
    "# 特徴量として使うモデルの集合\n",
    "def fit_base_models(X, y, models):\n",
    "    for model in models:\n",
    "        model.fit(X, y)\n",
    "# 最終的に予測するモデル\n",
    "def fit_meta_model(X, y):\n",
    "    model = LogisticRegression(solver = 'liblinear')\n",
    "#     model = GradientBoostingClassifier()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "# 評価用関数\n",
    "def evaluate_models(X, y, models):\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        mse = mean_squared_error(y, yhat)\n",
    "        print('%s: RMSE %.3f' % (model.__class__.__name__, sqrt(mse)))\n",
    "# super learner による予測\n",
    "def super_learner_predictions(X,models,meta_model):\n",
    "    meta_X = list()\n",
    "    for model in models:\n",
    "        yhat = model.predict(X)\n",
    "        meta_X.append(yhat.reshape(len(yhat),1))\n",
    "    meta_X = np.hstack(meta_X)\n",
    "    \n",
    "    return meta_model.predict(meta_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier: RMSE 0.187\n",
      "LogisticRegression: RMSE 0.170\n",
      "SVC: RMSE 0.171\n",
      "GaussianNB: RMSE 0.240\n",
      "KNeighborsClassifier: RMSE 0.172\n",
      "AdaBoostClassifier: RMSE 0.189\n",
      "BaggingClassifier: RMSE 0.175\n",
      "RandomForestClassifier: RMSE 0.171\n",
      "ExtraTreesClassifier: RMSE 0.170\n",
      "Super Learner: RMSE 0.164\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/chspred.csv')\n",
    "\n",
    "X = data.drop('mi',axis = 1)\n",
    "y = data['mi']\n",
    "\n",
    "X,X_val,y,y_val = train_test_split(X,y,test_size = 0.5,random_state = 33)\n",
    "\n",
    "models = get_models()\n",
    "\n",
    "meta_X,meta_y = get_out_of_fold_predictions(X.to_numpy(),y.to_numpy(),models)\n",
    "\n",
    "fit_base_models(X, y, models)\n",
    "\n",
    "meta_model = fit_meta_model(meta_X, meta_y)\n",
    "\n",
    "evaluate_models(X_val,y_val,models)\n",
    "yhat = super_learner_predictions(X_val, models, meta_model)\n",
    "print('Super Learner: RMSE %.3f' % (sqrt(mean_squared_error(y_val, yhat))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
